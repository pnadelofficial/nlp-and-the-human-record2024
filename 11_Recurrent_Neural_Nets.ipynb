{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w7XeSWa-_ILZ",
        "tzjYwyy5Ogrn",
        "SafG9zXlePLU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Translation (mostly) from Scratch using `PyTorch`\n",
        "\n",
        "###### Peter Nadel (primary author), Kyle Monahan, Joseph Robertson\n",
        "\n",
        "In this workshop, we'll build a machine translator using the neural net framework, `PyTorch`. We will implement the transformer architecture to translate between French and English. We'll then see an example using another dataset.\n",
        "\n",
        "Adapted from: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
      ],
      "metadata": {
        "id": "27Yisrr-zoOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make things run a bit faster, go to Runtime > Change runtime Type and select GPU under Hardware Accelerator."
      ],
      "metadata": {
        "id": "diAFxCp_IdBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_Pq_RuIyCp7"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "For this example, we'll use the `eng-fra.txt` from the `data.zip` file linked from the `PyTorch` page. This file, and all of those which we will look at in this notebook, will be arranged in the following way:\n",
        "\n",
        "`sentence_i in lang1\\tsentence_i in lang2\\n`.\n",
        "\n",
        "It should be noted that this is where this file comes from: https://www.manythings.org/anki/. There are several other languages here, all with varying corpus sizes. I assume the `PyTorch` folks chose French/English translation because of the size of the corpus (~14000 aligned sentences). Later in the notebook, I'll switch out this large aligned corpus with one of the smaller corpuses to anticipate working with Dakota."
      ],
      "metadata": {
        "id": "4_8w7jXazQ27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://tufts.box.com/shared/static/v5370zthsaiy5m5xqptv9clsndgyyx1i.zip'\n",
        "!mv v5370zthsaiy5m5xqptv9clsndgyyx1i.zip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpAC16sbKic5",
        "outputId": "ec98c2e6-0660-4a61-8e6c-2a34e1f7b5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-27 18:04:20--  https://tufts.box.com/shared/static/v5370zthsaiy5m5xqptv9clsndgyyx1i.zip\n",
            "Resolving tufts.box.com (tufts.box.com)... 74.112.186.144\n",
            "Connecting to tufts.box.com (tufts.box.com)|74.112.186.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/v5370zthsaiy5m5xqptv9clsndgyyx1i.zip [following]\n",
            "--2023-03-27 18:04:21--  https://tufts.box.com/public/static/v5370zthsaiy5m5xqptv9clsndgyyx1i.zip\n",
            "Reusing existing connection to tufts.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://tufts.app.box.com/public/static/v5370zthsaiy5m5xqptv9clsndgyyx1i.zip [following]\n",
            "--2023-03-27 18:04:21--  https://tufts.app.box.com/public/static/v5370zthsaiy5m5xqptv9clsndgyyx1i.zip\n",
            "Resolving tufts.app.box.com (tufts.app.box.com)... 74.112.186.144\n",
            "Connecting to tufts.app.box.com (tufts.app.box.com)|74.112.186.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl2.boxcloud.com/d/1/b1!I1gsfLkab6xff01hW4hSPBbJ4pEf5WOZKBffosrkgscCgGpPee7uirXn0tMES0WZGDQmqeFt4uJvubidwTxwoxbEM3lJrHQfhs3Pw9SM-x256oIbsBUnHOgoSnpzNNC5IwmnCjx-nt01mlz_1PiYCs3giWgU0pnJXaOztjhFNoTnHghjvsa1-EXan65OKSkoTkbfdZ_Nm9VOJ890m7uW0oyEJmaOLBYVaKrBIrof6750oGEWmkwbEiDYrsZHbehCiHeEj_PhiXxWT8PARTvQpu49GKVi9uUVMdJgx0oBROKc5K7cdAhCZMeiM2q1aZIOOyQ9t6rkzPsOJ5foU_Nt8NyFTRuMr4xKqJx0PmvNCOoJMv72rN8iv9b0YDyb2ffe-Rma8_nFwJub0iIKN-SFjOXxDKFcIYteNG5F3uerQS9N_5Lit0XWtLuFd4ydRF0J-IJCzBkp3iDZ3YKR1OhE4wYjIpchMe7b5EfaiTVhjQYCAA2c3hIrFAyDgHIdNDv_nuMVSxKI30QvqsAagxYVxRCiCchTu0dZxkA2eivcXHzcfdO77t2qjEIazb3BzKOY_an2BSLTvSYyumpDgChAy9rC1h6C8FfHUNqy6-WCVsefJVoNLLZY4THTApz4Cb02cmjxQeT4FRo6M4M7Lylv6sC9LwRvH61HW7L7jlhCfXOeAqV89tdaf_-lx7NCReptiVKbVrBVIhW_f7xgcllFK1SvExBkQTlH0nov4hXXeKjDzmUkVObLUJVAj47937MDxVnjl49nlxsSb5OHmlOL4tRztUh99yvnzXi84p7sq5XYrw3Eif2sn0ZTdmzZUoe1IFb_6bYelO4H1NM0C8TOHGMS7gN-ejdfJD_Wnrb-a3h9TMQTLQQi-swsJyEiyB5t2yx8bPxDTiENb71XWHj2eMM_XDAGJVCykyd-UXbJSr2e9PWV27_JXrkOglCkEBK-SZpln1I7aMvqJ23k3B_4moT7sXsFBH17dpVRCGSQkIg97rK27KKVyge88_uckqqsMBz3zB0Ha18ijgvwDkbjkm1WC7Zd7gjgOjXt8xUilz3FZg2q8U1IDj1j_deY7_Gsd5pstV5GFXpUoim1a69Ex3-zWMgeu_3QaEIICENBbB3Fnn4xSU1Zp2jlzMEFr_Lm4d22VnDEYF0mUAXz9lAKWkFBMl6fcA7iFaFemRU1VSmTK_xiDnPs7_lJmwk91kgmdmQOHO5rQuRXdt1ACM96WFrq0CLtWxkVwBM6JWSpNoNLzJ5vtDzNK-CgGmkd6GhqUWFuJwmXScnQ9pHzLkmUS068wrx0xv_FTr_f7WCm9ZNnudO6ZLzI3QMk7URKdWct188GwP4KKZsE8vYP13LhPqV48K2IxNXHvoyvAcxcINbQW7T5TpKr7i60wbpmbw-8Wl6V/download [following]\n",
            "--2023-03-27 18:04:22--  https://dl2.boxcloud.com/d/1/b1!I1gsfLkab6xff01hW4hSPBbJ4pEf5WOZKBffosrkgscCgGpPee7uirXn0tMES0WZGDQmqeFt4uJvubidwTxwoxbEM3lJrHQfhs3Pw9SM-x256oIbsBUnHOgoSnpzNNC5IwmnCjx-nt01mlz_1PiYCs3giWgU0pnJXaOztjhFNoTnHghjvsa1-EXan65OKSkoTkbfdZ_Nm9VOJ890m7uW0oyEJmaOLBYVaKrBIrof6750oGEWmkwbEiDYrsZHbehCiHeEj_PhiXxWT8PARTvQpu49GKVi9uUVMdJgx0oBROKc5K7cdAhCZMeiM2q1aZIOOyQ9t6rkzPsOJ5foU_Nt8NyFTRuMr4xKqJx0PmvNCOoJMv72rN8iv9b0YDyb2ffe-Rma8_nFwJub0iIKN-SFjOXxDKFcIYteNG5F3uerQS9N_5Lit0XWtLuFd4ydRF0J-IJCzBkp3iDZ3YKR1OhE4wYjIpchMe7b5EfaiTVhjQYCAA2c3hIrFAyDgHIdNDv_nuMVSxKI30QvqsAagxYVxRCiCchTu0dZxkA2eivcXHzcfdO77t2qjEIazb3BzKOY_an2BSLTvSYyumpDgChAy9rC1h6C8FfHUNqy6-WCVsefJVoNLLZY4THTApz4Cb02cmjxQeT4FRo6M4M7Lylv6sC9LwRvH61HW7L7jlhCfXOeAqV89tdaf_-lx7NCReptiVKbVrBVIhW_f7xgcllFK1SvExBkQTlH0nov4hXXeKjDzmUkVObLUJVAj47937MDxVnjl49nlxsSb5OHmlOL4tRztUh99yvnzXi84p7sq5XYrw3Eif2sn0ZTdmzZUoe1IFb_6bYelO4H1NM0C8TOHGMS7gN-ejdfJD_Wnrb-a3h9TMQTLQQi-swsJyEiyB5t2yx8bPxDTiENb71XWHj2eMM_XDAGJVCykyd-UXbJSr2e9PWV27_JXrkOglCkEBK-SZpln1I7aMvqJ23k3B_4moT7sXsFBH17dpVRCGSQkIg97rK27KKVyge88_uckqqsMBz3zB0Ha18ijgvwDkbjkm1WC7Zd7gjgOjXt8xUilz3FZg2q8U1IDj1j_deY7_Gsd5pstV5GFXpUoim1a69Ex3-zWMgeu_3QaEIICENBbB3Fnn4xSU1Zp2jlzMEFr_Lm4d22VnDEYF0mUAXz9lAKWkFBMl6fcA7iFaFemRU1VSmTK_xiDnPs7_lJmwk91kgmdmQOHO5rQuRXdt1ACM96WFrq0CLtWxkVwBM6JWSpNoNLzJ5vtDzNK-CgGmkd6GhqUWFuJwmXScnQ9pHzLkmUS068wrx0xv_FTr_f7WCm9ZNnudO6ZLzI3QMk7URKdWct188GwP4KKZsE8vYP13LhPqV48K2IxNXHvoyvAcxcINbQW7T5TpKr7i60wbpmbw-8Wl6V/download\n",
            "Resolving dl2.boxcloud.com (dl2.boxcloud.com)... 74.112.186.128\n",
            "Connecting to dl2.boxcloud.com (dl2.boxcloud.com)|74.112.186.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘v5370zthsaiy5m5xqptv9clsndgyyx1i.zip’\n",
            "\n",
            "v5370zthsaiy5m5xqpt 100%[===================>]   2.75M  2.60MB/s    in 1.1s    \n",
            "\n",
            "2023-03-27 18:04:25 (2.60 MB/s) - ‘v5370zthsaiy5m5xqptv9clsndgyyx1i.zip’ saved [2882130/2882130]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-p-kjc8ymWF",
        "outputId": "a3a313af-6ade-4448-aa2b-f0708944882b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'data/eng-fra.txt'"
      ],
      "metadata": {
        "id": "Gyu2KIrvyzoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can dig into this file, we need to make a class that will help us keep track of all of the words in our corpus. In particular, we need this case to do two things:\n",
        "\n",
        "*   Give each word a unique ID\n",
        "*   One-hot encode each word at the index of its ID\n",
        "*   This class will also give us the opportunity to encode our start of sentence (SOS) and end of sentence (EOS) tokens, which we'll place at the beginning and end of each sentence.\n",
        "\n",
        "Let's start by tracking how many times each word occurs."
      ],
      "metadata": {
        "id": "3hDNZH6X1VS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        word_list = sentence.replace('\\t', ' ').split(' ')\n",
        "        for word in word_list:\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1 # increments on each new word\n",
        "        else:\n",
        "            self.word2count[word] += 1 # increments on individual word"
      ],
      "metadata": {
        "id": "lH0TuWEu0R9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_data = open(data_path).readlines()\n",
        "ex_data[300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0gmU8ZZs3qIU",
        "outputId": "6acacf02-b184-4455-91b8-e930a3178f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm tidy.\\tJe suis ordonnée.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex = Lang('ex')\n",
        "ex.addSentence(ex_data[300])"
      ],
      "metadata": {
        "id": "nNOhZkrb5_NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex.word2index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1FkKzKb4Tda",
        "outputId": "45638145-82e4-4291-f2c4-6f5a955af4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"I'm\": 2, 'ugly.': 3, 'Je': 4, 'suis': 5, 'laid.\\n': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex.word2count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_d9-4J4eAV",
        "outputId": "df585448-1599-4485-dd7c-a476305fb671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"I'm\": 1, 'ugly.': 1, 'Je': 1, 'suis': 1, 'laid.\\n': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex.index2word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nhrW0Nq4fie",
        "outputId": "0c2df7ca-004d-429e-85d1-f1c2b59937a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'SOS', 1: 'EOS', 2: \"I'm\", 3: 'ugly.', 4: 'Je', 5: 'suis', 6: 'laid.\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a slight problem here. `I'm` is not a word. Instead, it's two words. In fact, we want our model to be able to understand contractions like this, but we'll first need to strip out all of the punctuation.\n",
        "\n",
        "Too, because this data is `unicode` encoded, we'll need to convert it to `ASCII`. This step will be especially important when we need to work with languages that do not use the Latin alphabet.\n",
        "\n",
        "The code below does both."
      ],
      "metadata": {
        "id": "3wDHWpZR625z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "eytSMSVW62NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split up I'm and normalized the text\n",
        "# we'll turn i m -> i am soon\n",
        "normalizeString(ex_data[300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Q2AuQDMc4hJ9",
        "outputId": "f01bf9bb-62aa-49cf-cae1-02a05d0beeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i m ugly . je suis laid .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set up a method to read in the whole file, pair up the aligned sentences and read them into our `Lang` class. We'll keep it as general as possible so we can swap in another dataset later."
      ],
      "metadata": {
        "id": "SO4LQAjw8_Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open(f'data/{lang1}-{lang2}.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line on the tab character and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs for when we want to go from lang2 to lang1\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "Ef_I2jCp8HCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also want a way to control the size of the sentence that we'll pass into our translator. Right now, we want to train a translator quickly so we'll set it to be small, but we can increase this for a better translator (that will take longer to train)."
      ],
      "metadata": {
        "id": "qB6H9taO94Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 50\n",
        "\n",
        "# dealing with most contractions\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "0I3uw7Gd9jXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The full data processing pipeline is as follows:\n",
        "\n",
        "*   Read text file and split into lines, then split those lines into pairs\n",
        "*   Normalize each pair and filter by length\n",
        "*   Make word lists from the sentence pairs\n",
        "\n",
        "We can stack everything together in the function below."
      ],
      "metadata": {
        "id": "nzd5fSs7-mLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "HRJsD75s-kPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp-56Fkq--dl",
        "outputId": "e1d5bbf6-4859-451c-acba-4976e7b2412d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 13067 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 5171\n",
            "eng 3389\n",
            "['je suis tres content de te revoir .', 'i m very glad to see you again .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Seq2Seq Model\n",
        "\n",
        "**Useful vocabulary for this section**\n",
        "\n",
        "*   Recurrent Neural Net (RNN) - a network that uses its output sequence as an input for subsequent steps.\n",
        "*   Seq2Seq network  or Encoder Decoder network - a model consisting of two RNNs: (1) an encoder that reads an input sequence and outputs a vector encoding of the sequence and (2) a decoder that reads the encoded vector and outputs a sequence.\n",
        "*   Hidden state - a layer of arbitrary size which comes does not come at the beginning or end of the network.\n",
        "*   [Gated Recurrent Unit (GRU)](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html) - a layer of a neural net which consturcts a hidden state at a given time step `t` from the hidden state of time `t-1`. It uses a `tanh` activation and passes all parameters through a sigmoid function.\n",
        "\n",
        "The Seq2Seq netowrk allows us to input an arbitrarily sized sentence in any language into the encoder and have the vector representation produced by the encoder be decoded into another language by the decoder.\n",
        "\n",
        "This architecture, though now used in other contexts, is ideal for machine translation. Even though words may come in different orders or are represented by multiple words in a target language, the transformer will be able to render a translation because it is decoding an vector encoded in a multilingual space.\n",
        "\n",
        "Finally, this architecture is easy(ish) to implement in `PyTorch` as we can first build the encoder and then the decoder then put them together.\n",
        "\n"
      ],
      "metadata": {
        "id": "w7XeSWa-_ILZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Encoder\n",
        "\n",
        "This piece of our Seq2Seq network will be a RNN that outputs some value for every word from the input sentence. For every input word, it will putput a vector and a hidden state, which will be used for the next imput word."
      ],
      "metadata": {
        "id": "P9JflJh0CF9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "-hnAnJkW-_Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To break this down a bit:\n",
        "\n",
        "*   Input is embedded by [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)\n",
        "*   Input embedding is activated with [`nn.GRU`](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html) and previous hidden state\n",
        "*   `nn.GRU` outputs an output embedding and another hidden state\n"
      ],
      "metadata": {
        "id": "u56o4Zp_FH3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Decoder\n",
        "\n",
        "This piece of out Seq2Seq network will be another RNN that take the encoder output (the embedding held by the variable `output` above) and will output a sequence of words that weill constitute the translation. We'll touch on two different type of decoders: a simple decoder and an attention decoder."
      ],
      "metadata": {
        "id": "22bJIpyNF1VJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simple decoder"
      ],
      "metadata": {
        "id": "Ix38w0lwGctj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "nJDLCz_dFxJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break this down again:\n",
        "\n",
        "*   Input (output of encoder) is embedded by `nn.Embedding`\n",
        "*   This embedding is activated by [`F.ReLu`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)\n",
        "*   An output and hidden state are created by passing the activated embedding through `nn.GRU`\n",
        "*   The hidden state is saved and the output is passed through a softmax layer to create probabilities from the embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "UM9FBNd7GlE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Decoder\n",
        "\n",
        "**What is attention**\n",
        "\n",
        "As we see above, the only language data being passed from the encoder to the decoder is the single vector output of `nn.GRU`. *Attention* allows the decoder to pay attention to different parts of the encoder's output. First, we'll calculate *attention weights* with a [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) layer using the decoder's input and the hidden state as inputs. These will be multiplied by the encoder output to create a combination (called `attn_applied` below) that will contain information about a specific part of the input and then help the decoder to choose the correct output words.\n",
        "\n",
        "*Note*: There are also other forms of attention, for example 'local attention'.\n",
        "\n",
        "See here for a diagram: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
      ],
      "metadata": {
        "id": "gfWRTm6MH_SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "FFGcvyeqGkgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can break this down the same way as with the simple decoder:\n",
        "\n",
        "*   First, the input is embedded using `nn.Embedding`\n",
        "*   Then, we pass this input into our attention layer using `nn.Linear` with the input as our x and the previous hidden state as the A in the linear transformation: $y = xA^{T} + b$ (this should look familiar from linear regression)\n",
        "*   From here, we follow the same steps as in the simple decoder. The attention layer is then combined with the original imput embedding and activated by `F.ReLu`\n",
        "*   As above, an output and hidden state are created by passing the activated embedding through `nn.GRU`\n",
        "*   The hidden state is saved and the output is passed through a softmax layer to create probabilities from the embedding"
      ],
      "metadata": {
        "id": "FJqxnPlEM6ke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Now that we understand the architecture of our network, we can begin training. First, we'll need to convert the indices of our sentence pairs into tensors which can be input into our encoder."
      ],
      "metadata": {
        "id": "tzjYwyy5Ogrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token) # appending the EOS token!\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "ifJfrkSmOgdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training function\n",
        "\n",
        "There is one final concept we need to explore before training our Seq2Seq network: *Teacher forcing*. Teacher forcing is when we use the true target outputs (in this case, the correct English language indices) as the each next input, instead of using the decoder's guess for that input. This allows the network to converge faster but can be abused if the dataset is not robust enough. We see that teacher-forced networks have much better understanding of grammar rules, but can stray from the correct translation easier. In fact, it has learned to represent the output grammar well, but not how to create the translation.\n",
        "\n",
        "`PyTorch` lets us implement teacher forcing with a simple `if` statement. Too, we can use `teacher_forcing_ratio` to control how much teacher forcing we want to use."
      ],
      "metadata": {
        "id": "iY6fe3r6P4Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden() # initalized the encoder\n",
        "\n",
        "    # zeroes encoder/decoder gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # input tensors from `tensorsFromPair`\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # encoder forward pass\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    # add SOS token to beginning of decoder input\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # decoder forward pass\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    # backward pass for whole Seq2Seq network\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "He2OiKiIM4kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities for timing\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "hG_HXgo7ScX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities for plotting\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "SuE8Ce7-TTkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation will do a foward pass in each RNN and return the words which are most likely\n",
        "# to be the translation of the input sentence as determined by softmax probabilities\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "bzpo4xW7Tkf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "NYmlne-maaRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training will proceed as follows:\n",
        "\n",
        "*   Start the timer\n",
        "*   Initialize optimizers and loss function\n",
        "*   Create training batch\n",
        "*   Record loss for plotting\n",
        "*   Evaluate our model\n",
        "\n"
      ],
      "metadata": {
        "id": "ud1ac-K0S8sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "h71cbho-S3Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training results"
      ],
      "metadata": {
        "id": "T12Mkf4VT6Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "I7OKnZygTYIH",
        "outputId": "ea0c8bab-cb44-4553-ad51-919f22fa72d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 25s (- 20m 1s) (5000 6%) 3.0698\n",
            "2m 48s (- 18m 12s) (10000 13%) 2.5384\n",
            "4m 14s (- 16m 57s) (15000 20%) 2.2402\n",
            "5m 38s (- 15m 31s) (20000 26%) 1.9931\n",
            "7m 6s (- 14m 12s) (25000 33%) 1.8022\n",
            "8m 29s (- 12m 44s) (30000 40%) 1.6516\n",
            "9m 53s (- 11m 18s) (35000 46%) 1.5201\n",
            "11m 17s (- 9m 52s) (40000 53%) 1.4076\n",
            "12m 41s (- 8m 27s) (45000 60%) 1.2953\n",
            "14m 4s (- 7m 2s) (50000 66%) 1.1893\n",
            "15m 28s (- 5m 37s) (55000 73%) 1.0975\n",
            "16m 53s (- 4m 13s) (60000 80%) 1.0386\n",
            "18m 18s (- 2m 48s) (65000 86%) 0.9832\n",
            "19m 42s (- 1m 24s) (70000 93%) 0.9107\n",
            "21m 6s (- 0m 0s) (75000 100%) 0.8556\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-ftzU88aPTS",
        "outputId": "c172a70e-00da-4cad-985c-91f7982b7919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> tu es son frere n est ce pas ?\n",
            "= you are his brother right ?\n",
            "< you are not ready with ? <EOS>\n",
            "\n",
            "> je suis promue .\n",
            "= i m being promoted .\n",
            "< i m being . <EOS>\n",
            "\n",
            "> soit il est saoul soit il est fou .\n",
            "= he is either drunk or mad .\n",
            "< he is crazy my my . . <EOS>\n",
            "\n",
            "> vous n etes pas fatigues si ?\n",
            "= you re not tired are you ?\n",
            "< you re not upset are you ? <EOS>\n",
            "\n",
            "> il a probablement tort .\n",
            "= he s probably wrong .\n",
            "< he s probably wrong . <EOS>\n",
            "\n",
            "> je vais bientot etre partie .\n",
            "= i m going to be gone soon .\n",
            "< i m going to be in big trouble . <EOS>\n",
            "\n",
            "> je suis puissant .\n",
            "= i m powerful .\n",
            "< i m powerful . <EOS>\n",
            "\n",
            "> vous etes degoutantes .\n",
            "= you re disgusting .\n",
            "< you re disgusting . <EOS>\n",
            "\n",
            "> je n ai pas l intention de preparer a diner pour vingt personnes .\n",
            "= i m not willing to cook dinner for twenty people .\n",
            "< i m not willing to stay dinner . . <EOS>\n",
            "\n",
            "> tu es la femme la plus belle du monde .\n",
            "= you re the most beautiful woman in the whole world .\n",
            "< you re the most beautiful woman in the world . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying a new dataset\n",
        "\n",
        "As I mentioned above, now that we have implemented the transformer architecture, we can now try on a new dataset, one that is comparable in size to the forthcoming Dakota dataset. In this example, I'll use [Breton](https://en.wikipedia.org/wiki/Breton_language), the language spoken by people living in Brittany, currently a part of France but was at one point a sovereign nation with its own language. Breton is one of the few remaining Celtic languages, the speakers of which, similar to the native Americans of this continent thousands of years later, were murdered and forcibly assimilated into Roman society during the conquests of Julius Caesar. Though speakers of Breton are few, they are tenacious.\n"
      ],
      "metadata": {
        "id": "SafG9zXlePLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip bre-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tdWNPMjfi8d",
        "outputId": "79f381e4-a123-4338-cd6f-381b435ca306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open bre-eng.zip, bre-eng.zip.zip or bre-eng.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there's some extra cleaning we need to do to make it look like the eng-fre dataset...\n",
        "!head bre.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1dszdDWfi5r",
        "outputId": "61bdc297-dd06-4d7a-ee95-fcce5aebc9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'bre.txt' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making a new file which we can pass into the data prep process\n",
        "raw = open('bre.txt').readlines()\n",
        "clean = [re.sub('(?=\\tCC).*','', r) for r in raw]\n",
        "clean[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwQ6yk_hfi0p",
        "outputId": "5a3a45ed-247a-4e85-ea87-a2e953f23b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thanks!\\tTrugarez !\\n',\n",
              " 'Thanks!\\tMersi !\\n',\n",
              " 'Thanks!\\tBennozh !\\n',\n",
              " 'Thanks.\\tTrugarez.\\n',\n",
              " 'Thanks.\\tMersi.\\n',\n",
              " 'Thanks.\\tBennozh.\\n',\n",
              " 'I eat bread.\\tBara a vez debret ganin.\\n',\n",
              " 'Many thanks.\\tMil drugarez.\\n',\n",
              " 'Many thanks.\\tMil bennozh.\\n',\n",
              " 'Are you here?\\tAmañ emaout ?\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('eng-bre.txt', 'w') as f:\n",
        "    for c in clean:\n",
        "        f.write(c)"
      ],
      "metadata": {
        "id": "qi4bY5wphkBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head eng-bre.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmiK8uhFhyxP",
        "outputId": "5fb75a59-c29c-4f3d-f62a-f50893f15ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thanks!\tTrugarez !\n",
            "Thanks!\tMersi !\n",
            "Thanks!\tBennozh !\n",
            "Thanks.\tTrugarez.\n",
            "Thanks.\tMersi.\n",
            "Thanks.\tBennozh.\n",
            "I eat bread.\tBara a vez debret ganin.\n",
            "Many thanks.\tMil drugarez.\n",
            "Many thanks.\tMil bennozh.\n",
            "Are you here?\tAmañ emaout ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# just need to move this file into the data directory\n",
        "!cp eng-bre.txt data"
      ],
      "metadata": {
        "id": "KEo9pww3iWoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 50\n",
        "\n",
        "def prepareData(lang1, lang2, trim=True, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    if trim:\n",
        "        pairs = filterPairs(pairs)\n",
        "        print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "X7ECy5nGiLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng', 'bre', False, True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddjhSDJxtfh6",
        "outputId": "151daadc-3497-4c8b-a5d4-e83a59952857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 196 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "bre 306\n",
            "eng 208\n",
            "['dav din mont .', 'i have to leave .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "ytFyfaYSiLu3",
        "outputId": "88cc5cf9-cbba-4fa7-88cc-c04d9952e297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 11s (- 16m 37s) (5000 6%) 1.2052\n",
            "2m 19s (- 15m 9s) (10000 13%) 0.0472\n",
            "3m 27s (- 13m 50s) (15000 20%) 0.0152\n",
            "4m 35s (- 12m 38s) (20000 26%) 0.0090\n",
            "5m 44s (- 11m 28s) (25000 33%) 0.0057\n",
            "6m 52s (- 10m 18s) (30000 40%) 0.0049\n",
            "8m 0s (- 9m 9s) (35000 46%) 0.0043\n",
            "9m 8s (- 8m 0s) (40000 53%) 0.0040\n",
            "10m 16s (- 6m 50s) (45000 60%) 0.0037\n",
            "11m 24s (- 5m 42s) (50000 66%) 0.0030\n",
            "12m 32s (- 4m 33s) (55000 73%) 0.0033\n",
            "13m 40s (- 3m 25s) (60000 80%) 0.0028\n",
            "14m 48s (- 2m 16s) (65000 86%) 0.0028\n",
            "15m 56s (- 1m 8s) (70000 93%) 0.0028\n",
            "17m 4s (- 0m 0s) (75000 100%) 0.0024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjhzVPXfrhNy",
        "outputId": "55840c0e-03c5-4291-e09a-1e7f6d64c402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> ur c harr az peus ?\n",
            "= do you have a car ?\n",
            "< do you have a car ? <EOS>\n",
            "\n",
            "> pegement eo ar montr man ?\n",
            "= how much is this watch ?\n",
            "< how much is this watch ? <EOS>\n",
            "\n",
            "> dont a ran eus tokyo bro japan .\n",
            "= i m from tokyo japan .\n",
            "< i m from tokyo japan . <EOS>\n",
            "\n",
            "> se n eo ket ur frazenn .\n",
            "= this is not a sentence .\n",
            "< this is not a sentence . <EOS>\n",
            "\n",
            "> me a wel un dra bennak .\n",
            "= i see something .\n",
            "< i see something . <EOS>\n",
            "\n",
            "> kelenn a blij din .\n",
            "= i love teaching .\n",
            "< i love teaching . <EOS>\n",
            "\n",
            "> o vervel e oant .\n",
            "= they were dying .\n",
            "< they were dying . <EOS>\n",
            "\n",
            "> n eus abeg ebet da vezan spontet .\n",
            "= there s no reason to be afraid .\n",
            "< there s no reason to be afraid . <EOS>\n",
            "\n",
            "> bez zo ur bern keriou bras e barzh ar brazil .\n",
            "= there are a lot of big cities in brazil .\n",
            "< there are a lot of big cities in brazil . <EOS>\n",
            "\n",
            "> n em eus ket kousket .\n",
            "= i haven t slept .\n",
            "< i haven t slept . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can save our models for later using pickle\n",
        "import pickle\n",
        "pickle.dump(encoder1, open(\"breton_english_encoder.p\", \"wb\" ))\n",
        "pickle.dump(attn_decoder1, open(\"breton_english_decoder.p\", \"wb\" ))"
      ],
      "metadata": {
        "id": "HYzfFOQj_CyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "Transformers take advantage of the sequential nature of the textual data which they encode and decode. That said, transformers are able to encode and decode much more than just aligned sentence pairs. In fact, they can be used with any sequential data, which ends up being most data in general. For instance, a system like ChatGPT learns how to answer questions through the same process. The question is encoded by an encoder and then the answer is decoded from that vector space by a decoder. Stable diffusion and other image generation models take in text and encode them and then decode an image.\n",
        "\n",
        "Too, encoding embeddings can be swapped out with pre-trained word embeddings from word2vec or GloVe. These encoding layers are amazing resources for research and can offer new insights into large datasets across the social sciences and the humanities."
      ],
      "metadata": {
        "id": "LKpyxn5neLsy"
      }
    }
  ]
}